{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook reproduces part some results of the paper:   \n",
    "\n",
    "@article{hansen2021frontiers,  \n",
    "  title={**Frontiers: Algorithmic collusion: Supra-competitive prices via independent algorithms**},  \n",
    "  author={Hansen, Karsten T and Misra, Kanishka and Pai, Mallesh M},  \n",
    "  journal={**Marketing Science**},  \n",
    "  volume={40},  \n",
    "  number={1},  \n",
    "  pages={1--12},  \n",
    "  year={2021},  \n",
    "  publisher={INFORMS}  \n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TL, DR**:\n",
    "\n",
    "This paper analysis the outcomes when two competing sllers (duopoly markets) use UCB algorithm to price homogeneious product dynamically. \n",
    "\n",
    "The profit function for each firm is stochastic: $\\pi_i(p_i, p_{-i}, \\delta)$, where $\\delta$ is clled the signal-to-noise ration (**SNR**). A higher $\\delta$ indicates lower stochasticity in profit.\n",
    "\n",
    "The system dynamics yield two possible outcomes:\n",
    "\n",
    "1. Convergence to Nash equilibrum;\n",
    "\n",
    "2. Convergence to a **supra-competitive** scenario resembling monopoly pricing.\n",
    "\n",
    "The learning algorithm is misspecified,  as the UCB algorithm neglects consideration of the competitor's decision.\n",
    "\n",
    "However, the numerical experiments reveal that the outcome depends on the SNR:\n",
    "\n",
    "1. when SNR is low: it's more likely to converge to the Nash-equilibrum;\n",
    "\n",
    "2. when SNR is high: it's more likely to converge to the supra-competitive scenario.\n",
    "\n",
    "The core of this paper consists of numerical expirements, complemented by straightforward mathematical proofs in the appendix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.random.seed(93)\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import json"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1: The Model Setting\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume there are 2 firms (denoted by $i, j$) selling a homogeneous product within an infinte time period. At each period $t$, firm $i$ gives price $p_{i,t}$ from a discrete space $P=\\{p_1, p_2, \\cdots, p_K\\}$. After facing the price $p_{-i,t}$ by the competitor, the profit can be obtained through a parametric data-generating process (DGP):\n",
    "\n",
    "$$\n",
    "\\pi_{i,t} = (\\alpha - \\beta p_{i,t} + \\gamma p_{-i, t})\\cdot p_{i,t} + \\epsilon_t, \\\\\n",
    "\\epsilon_t \\sim U[-\\frac1\\delta,\\frac1\\delta],\n",
    "$$\n",
    "where $\\delta$ is called the signal-to-noise ratio (**SNR**).\n",
    "\n",
    "From the DGP we can observe:\n",
    "\n",
    "1. The marginal cost of the product is zero;\n",
    "2. The demand function is deterministic, the random term is added to the profit only;\n",
    "3. The SNR is inversely proportional to the stability of the profit;\n",
    "4. The demand function is symmetric for both firms.\n",
    "\n",
    "Under such settings, we can calculate the prices under Nash equilibrium (the competitive case) or under collusive pricing (the supra-competitive case) analytically:\n",
    "\n",
    "$$\n",
    "Competitive: p^D = \\frac{\\alpha}{2\\beta-\\gamma} \\\\\n",
    "Collusive: p^M = \\frac{\\alpha}{2(\\beta-\\gamma)}\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hansen_env():\n",
    "\n",
    "    def __init__(self, info):\n",
    "        \"\"\"\n",
    "        The input parameters info should be dictionary.\n",
    "        info should contain keys: 'alpha', 'beta', 'gamma', 'delta'\n",
    "        \"\"\"\n",
    "        self.info = info\n",
    "        self.rewards_log = []\n",
    "        self.actions_log = []\n",
    "        self.prices_log = []\n",
    "        self.action_spaces = None\n",
    "        self.nash = None\n",
    "        self.collusion = None\n",
    "        self.check()\n",
    "        self.initialize()\n",
    "    \n",
    "    def check(self):\n",
    "        keys = ['alpha', 'beta', 'gamma', 'delta']\n",
    "        if not all(key in self.info for key in keys):\n",
    "            raise ValueError(\"Incorrect Parameters\")\n",
    "        \n",
    "    def step(self, actions):\n",
    "        self.actions_log.append(actions)\n",
    "        prices = self.action_spaces[0][actions[0]], self.action_spaces[1][actions[1]]\n",
    "        self.prices_log.append(prices)\n",
    "        rewards = self.execute(prices)\n",
    "        self.rewards_log.append(rewards)\n",
    "        return rewards\n",
    "    \n",
    "    def execute(self, prices):\n",
    "        profit1 = (prices[0] * (self.info['alpha']-self.info['beta']*prices[0]+self.info['gamma']*prices[1])) + np.random.uniform(-1/self.info['delta'], 1/self.info['delta'])\n",
    "        profit2 = (prices[1] * (self.info['alpha']-self.info['beta']*prices[1]+self.info['gamma']*prices[0])) + np.random.uniform(-1/self.info['delta'], 1/self.info['delta'])\n",
    "        return np.maximum(0, (profit1, profit2))\n",
    "    \n",
    "    def initialize(self):\n",
    "        \"\"\"\n",
    "        Compute the nash, collusion prices and the actions spaces.\n",
    "        \"\"\"\n",
    "        nash = self.info['alpha'] / (2*self.info['beta']-self.info['gamma']) \n",
    "        self.nash = np.array([nash, nash])\n",
    "        collusion = 0.5 * self.info['alpha'] / (self.info['beta']-self.info['gamma']) \n",
    "        self.collusion = np.array([collusion, collusion])\n",
    "        self.action_spaces = [np.array([nash, collusion]), np.array([nash, collusion])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the baseline model, the action space for each agent is $2$, meaning each agent can only pick price from the $p^D$ and $p^M$. \n",
    "\n",
    "The agent utilizes $UCB-tuned$ algorithm to make decision at time $t$:\n",
    "\n",
    "\\begin{aligned}\n",
    "V_{k,t}& =\\overline{\\pi_{k,t}^{2}}-\\bar{\\pi}_{k,t}^{2}+\\sqrt{\\frac{2\\log t}{n_{k,t}}},  \\\\\n",
    "\\mathrm{UCB-tuned}_{k,t}& =\\bar{\\pi}_{k,t}+\\sqrt{\\frac{\\log t}{n_{k,t}}\\mathrm{min}\\left(\\frac14,\\mathrm{V}_{k,t}\\right),} \n",
    "\\end{aligned}\n",
    "\n",
    "where \\(n_{k, t}\\) represents the frequency of the agent taking action \\(k\\) up to time \\(t\\).To give an intuitive understanding on the formula:\n",
    "\n",
    "1. The term $\\overline{\\pi_{k,t}^{2}}-\\bar{\\pi}_{k,t}^{2}$ is the empirical variance.\n",
    "\n",
    "2. The term $\\sqrt{\\frac{\\log t}{n_{k,t}}\\mathrm{min}(\\frac14,\\mathrm{V}_{k,t})}$ is used for exploratin.\n",
    "\n",
    "The agent pick action $k$ at time $t$ with the highest index $\\mathrm{UCB-tuned}_{k,t}$.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Hansen_agent:\n",
    "    def __init__(self):\n",
    "        self.t = 0\n",
    "        self.n = np.array([0, 0])\n",
    "        self.last_action = None\n",
    "        self.reward = [[], []]\n",
    "        self.mean = np.empty(2)\n",
    "        self.mean2 = np.empty(2)\n",
    "\n",
    "    def action(self):\n",
    "        temp = np.sqrt(2 * np.log(self.t) / self.n)\n",
    "        V = self.mean2 - self.mean**2 + temp\n",
    "        temp = np.log(self.t) / self.n\n",
    "        temp *= np.minimum(0.25, V)\n",
    "        UCB = self.mean + np.sqrt(temp)\n",
    "        action = np.argmax(UCB)\n",
    "        self.last_action = action\n",
    "        return action\n",
    "\n",
    "    def update(self, reward):\n",
    "        self.t += 1\n",
    "        self.n[self.last_action] += 1\n",
    "        self.reward[self.last_action].append(reward)\n",
    "        self.mean[self.last_action] += (reward - self.mean[self.last_action]) / (self.n[self.last_action] + 1)  \n",
    "        self.mean2[self.last_action] += (reward**2 - self.mean2[self.last_action]) / (self.n[self.last_action] + 1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the agents have no information on the bandit at the beginning of the game, they explore randomly at the first two rounds:\n",
    "\n",
    "1. In the first round, each agent randomly selects one action.\n",
    "2. In the second round, each agent chooses the opposite action to that of the first round (there are 2 actins in total).\n",
    "3. Subsequently, each agent makes decisions using the UCB-tuned algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def initialize(env, agent1, agent2):\n",
    "    action1 = np.random.choice(np.array(2), 2)\n",
    "    agent1.last_action, agent2.last_action = action1\n",
    "    rewards = env.step((agent1.last_action, agent2.last_action))\n",
    "    agent1.update(rewards[0])\n",
    "    agent2.update(rewards[1])\n",
    "    agent1.last_action, agent2.last_action = 1 - action1\n",
    "    rewards = env.step((agent1.last_action, agent2.last_action))\n",
    "    agent1.update(rewards[0])\n",
    "    agent2.update(rewards[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we can use the parameters set in the paper to construct an environment for interaction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "info = {'alpha': 0.48, 'beta': 0.9, 'gamma': 0.6, 'delta': 0.1}\n",
    "env = Hansen_env(info)\n",
    "agent1, agent2 = Hansen_agent(), Hansen_agent()\n",
    "initialize(env, agent1, agent2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 2: The Main Resuts\n",
    "\n",
    "In the paper, the authors dicuss the impact of *SNR* on the pricing outcome. \n",
    "\n",
    "For each given SNR, 500 Monte Carlo Simulations are performed. For each simulation, we consider the **median price** charged in the last 1,000 rounds out of two million rounds.\n",
    "\n",
    "<div style=\"text-align:center;\">\n",
    "    <img src=\"pic/pic1.png\" alt=\"Alt text\" style=\"display:inline-block;width:450px; height:450px;\">\n",
    "</div>\n",
    "\n",
    "In this notbook, to reduce the computational time, I "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delta = 0.1:   0%|          | 0/500 [00:00<?, ?item/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "delta = 0.1: 100%|██████████| 500/500 [11:31<00:00,  1.38s/item]\n",
      "delta = 0.2: 100%|██████████| 500/500 [09:00<00:00,  1.08s/item]\n",
      "delta = 0.4: 100%|██████████| 500/500 [08:48<00:00,  1.06s/item]\n",
      "delta = 1: 100%|██████████| 500/500 [09:18<00:00,  1.12s/item]\n",
      "delta = 2.5: 100%|██████████| 500/500 [10:07<00:00,  1.21s/item]\n",
      "delta = 5: 100%|██████████| 500/500 [11:11<00:00,  1.34s/item]\n",
      "delta = 10: 100%|██████████| 500/500 [09:58<00:00,  1.20s/item]\n"
     ]
    }
   ],
   "source": [
    "delta_list = [0.1, 0.2, 0.4, 1, 2.5, 5, 10]\n",
    "results = {delta:[] for delta in delta_list}\n",
    "for delta in delta_list:\n",
    "    for _ in tqdm(range(500), desc=\"delta = {}\".format(delta), unit=\"item\"):\n",
    "        info = {'alpha': 0.48, 'beta': 0.9, 'gamma': 0.6, 'delta': 0.1}\n",
    "        env = Hansen_env(info)\n",
    "        agent1, agent2 = Hansen_agent(), Hansen_agent()\n",
    "        initialize(env, agent1, agent2)\n",
    "        for __ in range(20000 - 2):\n",
    "            actions = (agent1.action(), agent2.action())\n",
    "            rewards = env.step(actions)\n",
    "            agent1.update(rewards[0])\n",
    "            agent2.update(rewards[1])\n",
    "        prices = np.array(env.prices_log)[-100:, :]\n",
    "        price1, price2 = np.median(prices[:, 0]), np.median(prices[:, 1])\n",
    "        results[delta].append([price1, price2])\n",
    "with open('data/hansen2021frontiers_results.json', 'w') as json_file:\n",
    "    json.dump(results, json_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "While these are merely small-scale numerical experiments, their execution consumes a significant amount of time. If readers think it is time-consuming, they can continue the folliwing analysis by directly running the code below to load the preprocessed data stored in the file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('data/hansen2021frontiers_results.json', 'r') as data:\n",
    "    results = json.load(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "for delta in delta_list:\n",
    "    data = np.array(results[str(delta)])\n",
    "    temp = data[:, 0] - data[:, 1]\n",
    "    print(np.median(temp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1.32119064,  0.12837629])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.mean"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3: Robust Tests & Proof"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RL",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
